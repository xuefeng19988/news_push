#!/usr/bin/env python3
"""
æµ‹è¯•å»ºè®®çš„æ–°æ–°é—»æº
"""

import feedparser
import requests
import time
import json
from datetime import datetime
from typing import Tuple

def test_rss_source(url: str, name: str) -> Tuple[bool, str, int]:
    """æµ‹è¯•RSSæº"""
    try:
        start_time = time.time()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        feed = feedparser.parse(url)
        elapsed = time.time() - start_time
        
        if feed.bozo:
            return False, f"è§£æžé”™è¯¯: {feed.bozo_exception}", 0
        
        if not feed.entries:
            return False, "æ— æ–‡ç« å†…å®¹", 0
        
        article_count = len(feed.entries)
        return True, f"æˆåŠŸèŽ·å– {article_count} ç¯‡æ–‡ç«  ({elapsed:.1f}ç§’)", article_count
        
    except Exception as e:
        return False, f"å¼‚å¸¸: {str(e)}", 0

# è¦æµ‹è¯•çš„æ–°æ–°é—»æº
new_sources_to_test = [
    # å›½é™…é«˜è´¨é‡åª’ä½“
    {
        'name': 'ç»æµŽå­¦äºº (The Economist)',
        'type': 'rss',
        'url': 'https://www.economist.com/rss',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'çº½çº¦å®¢ (The New Yorker)',
        'type': 'rss', 
        'url': 'https://www.newyorker.com/rss',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'åŽå°”è¡—æ—¥æŠ¥ (Wall Street Journal)',
        'type': 'rss',
        'url': 'https://feeds.a.dj.com/rss/RSSWorldNews.xml',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'è·¯é€ç¤¾ (Reuters)',
        'type': 'rss',
        'url': 'http://feeds.reuters.com/reuters/topNews',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'ç¾Žè”ç¤¾ (Associated Press)',
        'type': 'rss',
        'url': 'https://apnews.com/rss',
        'category': 'å›½é™…åª’ä½“'
    },
    
    # ç§‘æŠ€åª’ä½“
    {
        'name': 'TechCrunch',
        'type': 'rss',
        'url': 'http://feeds.feedburner.com/TechCrunch/',
        'category': 'ç§‘æŠ€åª’ä½“'
    },
    {
        'name': 'Wired',
        'type': 'rss',
        'url': 'https://www.wired.com/feed/rss',
        'category': 'ç§‘æŠ€åª’ä½“'
    },
    
    # ä¸­æ–‡ä¼˜è´¨åª’ä½“
    {
        'name': 'è´¢æ–°ç½‘',
        'type': 'rss',
        'url': 'https://rss.caixin.com/',
        'category': 'å›½å†…åª’ä½“'
    },
    {
        'name': 'è™Žå—…',
        'type': 'rss',
        'url': 'https://www.huxiu.com/rss/0.xml',
        'category': 'å›½å†…åª’ä½“'
    },
    {
        'name': '36æ°ª',
        'type': 'rss',
        'url': 'https://www.36kr.com/feed',
        'category': 'å›½å†…åª’ä½“'
    }
]

def main():
    print("ðŸ” æµ‹è¯•å»ºè®®çš„æ–°æ–°é—»æº")
    print("=" * 80)
    
    results = []
    
    for source in new_sources_to_test:
        print(f"æµ‹è¯•: {source['name']} ({source['category']})")
        print(f"  URL: {source['url']}")
        
        success, message, count = test_rss_source(source['url'], source['name'])
        
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"  çŠ¶æ€: {status}")
        print(f"  ä¿¡æ¯: {message}")
        print(f"  æ•°é‡: {count}")
        print()
        
        results.append({
            'name': source['name'],
            'category': source['category'],
            'url': source['url'],
            'success': success,
            'message': message,
            'count': count
        })
    
    # ç»Ÿè®¡
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print("=" * 80)
    print(f"ðŸ“Š æµ‹è¯•ç»“æžœ: {len(successful)}/{len(results)} æˆåŠŸ")
    print()
    
    if successful:
        print("âœ… æˆåŠŸçš„æ–°é—»æº:")
        for r in sorted(successful, key=lambda x: x['count'], reverse=True):
            print(f"  â€¢ {r['name']}: {r['count']} ç¯‡æ–‡ç« ")
        print()
    
    if failed:
        print("âŒ å¤±è´¥çš„æ–°é—»æº:")
        for r in failed:
            print(f"  â€¢ {r['name']}: {r['message']}")
        print()
    
    # ä¿å­˜ç»“æžœ
    with open('new_sources_test_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ðŸ“ ç»“æžœå·²ä¿å­˜åˆ°: new_sources_test_results.json")
    
    # æŽ¨èæ·»åŠ çš„æº
    print("\nðŸ’¡ æŽ¨èæ·»åŠ çš„æ–°é—»æº (æˆåŠŸä¸”æ–‡ç« æ•°é‡å¤š):")
    good_sources = [r for r in successful if r['count'] >= 10]
    for r in sorted(good_sources, key=lambda x: x['count'], reverse=True):
        print(f"  â€¢ {r['name']} ({r['category']}): {r['count']} ç¯‡æ–‡ç« ")

if __name__ == "__main__":
    main()