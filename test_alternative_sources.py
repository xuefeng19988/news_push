#!/usr/bin/env python3
"""
æµ‹è¯•æ›¿ä»£çš„æ–°é—»æº
å¯»æ‰¾æ›´å¤šå¯ç”¨çš„RSSæº
"""

import feedparser
import time
import json
from datetime import datetime
from typing import Tuple

def test_rss_source(url: str, name: str) -> Tuple[bool, str, int]:
    """æµ‹è¯•RSSæº"""
    try:
        start_time = time.time()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        feed = feedparser.parse(url)
        elapsed = time.time() - start_time
        
        if feed.bozo:
            return False, f"è§£æé”™è¯¯: {feed.bozo_exception}", 0
        
        if not feed.entries:
            return False, "æ— æ–‡ç« å†…å®¹", 0
        
        article_count = len(feed.entries)
        return True, f"æˆåŠŸè·å– {article_count} ç¯‡æ–‡ç«  ({elapsed:.1f}ç§’)", article_count
        
    except Exception as e:
        return False, f"å¼‚å¸¸: {str(e)}", 0

# æ›¿ä»£çš„æ–°é—»æºï¼ˆç»è¿‡éªŒè¯å¯ç”¨çš„ï¼‰
alternative_sources = [
    # å›½é™…åª’ä½“ - æ›¿ä»£æº
    {
        'name': 'BBC News',
        'type': 'rss',
        'url': 'http://feeds.bbci.co.uk/news/rss.xml',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'CNN',
        'type': 'rss',
        'url': 'http://rss.cnn.com/rss/cnn_topstories.rss',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'The Guardian',
        'type': 'rss',
        'url': 'https://www.theguardian.com/world/rss',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'Al Jazeera',
        'type': 'rss',
        'url': 'https://www.aljazeera.com/xml/rss/all.xml',
        'category': 'å›½é™…åª’ä½“'
    },
    {
        'name': 'Bloomberg',
        'type': 'rss',
        'url': 'https://www.bloomberg.com/feeds/podcasts/etf-report.rss',
        'category': 'å›½é™…åª’ä½“'
    },
    
    # ç§‘æŠ€åª’ä½“ - æ›´å¤šé€‰æ‹©
    {
        'name': 'The Verge',
        'type': 'rss',
        'url': 'https://www.theverge.com/rss/index.xml',
        'category': 'ç§‘æŠ€åª’ä½“'
    },
    {
        'name': 'Engadget',
        'type': 'rss',
        'url': 'https://www.engadget.com/rss.xml',
        'category': 'ç§‘æŠ€åª’ä½“'
    },
    {
        'name': 'Mashable',
        'type': 'rss',
        'url': 'http://feeds.mashable.com/Mashable',
        'category': 'ç§‘æŠ€åª’ä½“'
    },
    
    # ä¸­æ–‡åª’ä½“ - æ›¿ä»£æº
    {
        'name': 'æœç‹æ–°é—»',
        'type': 'rss',
        'url': 'http://rss.news.sohu.com/rss/focus.xml',
        'category': 'å›½å†…åª’ä½“'
    },
    {
        'name': 'è…¾è®¯æ–°é—»',
        'type': 'rss',
        'url': 'http://news.qq.com/newsgn/rss_newsgn.xml',
        'category': 'å›½å†…åª’ä½“'
    },
    {
        'name': 'äººæ°‘ç½‘',
        'type': 'rss',
        'url': 'http://www.people.com.cn/rss/politics.xml',
        'category': 'å›½å†…åª’ä½“'
    },
    {
        'name': 'æ–°åç½‘',
        'type': 'rss',
        'url': 'http://www.xinhuanet.com/rss/world.xml',
        'category': 'å›½å†…åª’ä½“'
    },
    
    # è´¢ç»åª’ä½“
    {
        'name': 'CNBC',
        'type': 'rss',
        'url': 'https://www.cnbc.com/id/100003114/device/rss/rss.html',
        'category': 'è´¢ç»åª’ä½“'
    },
    {
        'name': 'Financial Times',
        'type': 'rss',
        'url': 'https://www.ft.com/?format=rss',
        'category': 'è´¢ç»åª’ä½“'
    },
    
    # åŒºåŸŸåª’ä½“
    {
        'name': 'Straits Times',
        'type': 'rss',
        'url': 'https://www.straitstimes.com/news/rss.xml',
        'category': 'åŒºåŸŸåª’ä½“'
    },
    {
        'name': 'South China Morning Post',
        'type': 'rss',
        'url': 'https://www.scmp.com/rss/2/feed',
        'category': 'åŒºåŸŸåª’ä½“'
    }
]

def main():
    print("ğŸ” æµ‹è¯•æ›¿ä»£æ–°é—»æº")
    print("=" * 80)
    
    results = []
    
    for source in alternative_sources:
        print(f"æµ‹è¯•: {source['name']} ({source['category']})")
        print(f"  URL: {source['url']}")
        
        success, message, count = test_rss_source(source['url'], source['name'])
        
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"  çŠ¶æ€: {status}")
        print(f"  ä¿¡æ¯: {message}")
        print(f"  æ•°é‡: {count}")
        print()
        
        results.append({
            'name': source['name'],
            'category': source['category'],
            'url': source['url'],
            'success': success,
            'message': message,
            'count': count
        })
    
    # ç»Ÿè®¡
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print("=" * 80)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {len(successful)}/{len(results)} æˆåŠŸ")
    print()
    
    if successful:
        print("âœ… æˆåŠŸçš„æ–°é—»æº (æŒ‰æ–‡ç« æ•°é‡æ’åº):")
        for r in sorted(successful, key=lambda x: x['count'], reverse=True):
            print(f"  â€¢ {r['name']} ({r['category']}): {r['count']} ç¯‡æ–‡ç« ")
        print()
    
    if failed:
        print("âŒ å¤±è´¥çš„æ–°é—»æº:")
        for r in failed:
            print(f"  â€¢ {r['name']}: {r['message']}")
        print()
    
    # ä¿å­˜ç»“æœ
    with open('alternative_sources_test_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: alternative_sources_test_results.json")
    
    # æœ€ç»ˆæ¨è
    print("\nğŸ’¡ æœ€ç»ˆæ¨èæ·»åŠ çš„æ–°é—»æº:")
    good_sources = [r for r in successful if r['count'] >= 10]
    categories = {}
    
    for r in sorted(good_sources, key=lambda x: x['count'], reverse=True):
        cat = r['category']
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(r)
    
    for cat, sources in categories.items():
        print(f"\n{cat}:")
        for r in sources[:3]:  # æ¯ä¸ªç±»åˆ«æœ€å¤šæ¨è3ä¸ª
            print(f"  â€¢ {r['name']}: {r['count']} ç¯‡æ–‡ç« ")

if __name__ == "__main__":
    main()