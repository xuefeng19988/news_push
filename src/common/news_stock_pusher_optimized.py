#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæ–°é—»+è‚¡ç¥¨æ¨é€ç³»ç»Ÿ
ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·æ¨¡å—ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 
"""

import os
import sys
import json
import time
import requests
from datetime import datetime, timedelta
import re
from typing import List, Dict, Any, Optional

# å¯¼å…¥å·¥å…·æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.database import NewsDatabase
from utils.config import ConfigManager, load_env_config
from utils.logger import Logger

class NewsStockPusherOptimized:
    """ä¼˜åŒ–ç‰ˆæ–°é—»+è‚¡ç¥¨æ¨é€å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–é…ç½®
        self.config_mgr = ConfigManager()
        self.env_config = load_env_config()
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = Logger("news_stock_pusher", level="INFO").get_logger()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self.db = NewsDatabase(self.env_config.get("DATABASE_PATH", "./news_cache.db"))
        
        # åˆå§‹åŒ–HTTPä¼šè¯
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })
        
        # åŠ è½½è‚¡ç¥¨é…ç½®
        self.stock_config = self.config_mgr.get_config("clawdbot_stock_config.json")
        self.stocks = self.stock_config.get("stocks", [])
        
        # æ–°é—»æºé…ç½®
        self.news_sources = self._get_news_sources()
        
        self.logger.info("æ–°é—»è‚¡ç¥¨æ¨é€å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _get_news_sources(self) -> List[Dict[str, Any]]:
        """è·å–æ–°é—»æºé…ç½®"""
        return [
            # å›½é™…æ–°é—»
            {"name": "BBC News", "url": "http://feeds.bbci.co.uk/news/world/rss.xml", "type": "rss"},
            {"name": "CNN", "url": "http://rss.cnn.com/rss/edition.rss", "type": "rss"},
            {"name": "Financial Times", "url": "https://www.ft.com/?format=rss", "type": "rss"},
            {"name": "Nikkei Asia", "url": "https://asia.nikkei.com/rss/feed/nar", "type": "rss"},
            {"name": "SCMP", "url": "https://www.scmp.com/rss/91/feed", "type": "rss"},
            
            # ä¸­å›½æ–°é—»
            {"name": "æ¾æ¹ƒæ–°é—»", "url": "https://www.thepaper.cn/feed_channel_25950", "type": "rss"},
            {"name": "æ–°æµªè´¢ç»", "url": "http://finance.sina.com.cn/roll/index.d.html?cid=56578", "type": "html"},
            
            # ç¤¾äº¤åª’ä½“
            {"name": "å¾®åšçƒ­æœ", "url": "https://s.weibo.com/top/summary", "type": "weibo"},
            {"name": "Redditçƒ­é—¨", "url": "https://www.reddit.com/r/all/hot.json", "type": "reddit"},
        ]
    
    def fetch_news_from_rss(self, rss_url: str, source: str) -> List[Dict[str, Any]]:
        """ä»RSSæºè·å–æ–°é—»"""
        try:
            response = self.session.get(rss_url, timeout=10)
            response.raise_for_status()
            
            articles = []
            
            # ç®€åŒ–çš„RSSè§£æï¼ˆå®é™…åº”ä½¿ç”¨feedparseråº“ï¼‰
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„è§£æé€»è¾‘
            content = response.text
            
            # æŸ¥æ‰¾æ–‡ç« é¡¹
            import re
            item_pattern = r'<item>.*?</item>'
            items = re.findall(item_pattern, content, re.DOTALL)
            
            for item in items[:10]:  # é™åˆ¶æ•°é‡
                # æå–æ ‡é¢˜
                title_match = re.search(r'<title>(.*?)</title>', item)
                title = title_match.group(1).strip() if title_match else "æ— æ ‡é¢˜"
                
                # æå–é“¾æ¥
                link_match = re.search(r'<link>(.*?)</link>', item)
                url = link_match.group(1).strip() if link_match else ""
                
                # æå–æè¿°
                desc_match = re.search(r'<description>(.*?)</description>', item)
                description = desc_match.group(1).strip() if desc_match else ""
                
                # æå–å‘å¸ƒæ—¶é—´
                pub_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                pub_date = pub_match.group(1).strip() if pub_match else ""
                
                if title and url:
                    articles.append({
                        "title": title,
                        "url": url,
                        "description": description,
                        "pub_date": pub_date,
                        "source": source
                    })
            
            self.logger.info(f"ä» {source} è·å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
            return articles
            
        except Exception as e:
            self.logger.error(f"è·å– {source} RSSæ–°é—»å¤±è´¥: {e}")
            return []
    
    def fetch_all_news(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ–°é—»æºçš„æ–°é—»"""
        all_articles = []
        
        for source in self.news_sources:
            try:
                if source["type"] == "rss":
                    articles = self.fetch_news_from_rss(source["url"], source["name"])
                    all_articles.extend(articles)
                
                # å¯ä»¥æ·»åŠ å…¶ä»–ç±»å‹çš„æ–°é—»æºå¤„ç†
                
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                self.logger.error(f"å¤„ç†æ–°é—»æº {source['name']} å¤±è´¥: {e}")
                continue
        
        return all_articles
    
    def filter_new_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¿‡æ»¤å·²æ¨é€çš„æ–‡ç« """
        new_articles = []
        
        for article in articles:
            if not self.db.is_article_pushed(article["title"], article["url"]):
                new_articles.append(article)
        
        self.logger.info(f"è¿‡æ»¤åæ–°æ–‡ç« : {len(new_articles)}/{len(articles)}")
        return new_articles
    
    def get_stock_data(self, stock_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„è‚¡ç¥¨æ•°æ®è·å–
            # å®é™…åº”ä½¿ç”¨Yahoo Finance APIæˆ–å…¶ä»–è‚¡ç¥¨API
            symbol = stock_info.get("yahoo_symbol", stock_info.get("symbol", ""))
            
            # æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
            import random
            base_price = 100 + random.uniform(-20, 20)
            change = random.uniform(-5, 5)
            change_percent = (change / base_price) * 100
            
            return {
                "name": stock_info.get("name", ""),
                "symbol": stock_info.get("symbol", ""),
                "price": round(base_price, 2),
                "change": round(change, 2),
                "change_percent": round(change_percent, 2),
                "currency": stock_info.get("currency", "USD"),
                "volume": random.randint(1000000, 10000000),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥ {stock_info.get('name')}: {e}")
            return None
    
    def get_all_stocks_data(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®"""
        stocks_data = []
        
        for stock in self.stocks:
            data = self.get_stock_data(stock)
            if data:
                stocks_data.append(data)
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        self.logger.info(f"è·å–åˆ° {len(stocks_data)} åªè‚¡ç¥¨æ•°æ®")
        return stocks_data
    
    def generate_summary(self, description: str, max_length: int = 150) -> str:
        """ç”Ÿæˆæ–‡ç« æ‘˜è¦"""
        if not description:
            return "æš‚æ— æ‘˜è¦"
        
        # æ¸…ç†HTMLæ ‡ç­¾
        import re
        clean_text = re.sub(r'<[^>]+>', '', description)
        
        # æˆªå–åˆé€‚é•¿åº¦
        if len(clean_text) <= max_length:
            return clean_text
        
        # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', clean_text)
        summary = ""
        
        for sentence in sentences:
            if sentence.strip():
                if len(summary + sentence) > max_length:
                    break
                summary += sentence + "."
        
        if not summary:
            summary = clean_text[:max_length] + "..."
        
        return summary.strip()
    
    def calculate_importance_score(self, article: Dict[str, Any]) -> int:
        """è®¡ç®—æ–‡ç« é‡è¦æ€§åˆ†æ•°"""
        score = 0
        
        # æ¥æºæƒé‡
        source = article.get("source", "").lower()
        if "bbc" in source or "cnn" in source:
            score += 30
        elif "financial" in source or "ft" in source:
            score += 25
        elif "nikkei" in source or "scmp" in source:
            score += 20
        elif "thepaper" in source or "æ¾æ¹ƒ" in source:
            score += 15
        
        # æ ‡é¢˜å…³é”®è¯
        title = article.get("title", "").lower()
        important_keywords = [
            "breaking", "ç´§æ€¥", "çªå‘", "crisis", "å±æœº",
            "war", "æˆ˜äº‰", "conflict", "å†²çª", "alert", "è­¦æŠ¥"
        ]
        
        for keyword in important_keywords:
            if keyword in title:
                score += 20
                break
        
        # æè¿°é•¿åº¦
        description = article.get("description", "")
        if len(description) > 200:
            score += 10
        
        return min(score, 100)  # é™åˆ¶æœ€å¤§åˆ†æ•°
    
    def get_importance_level(self, score: int) -> str:
        """è·å–é‡è¦æ€§çº§åˆ«"""
        if score >= 70:
            return "ğŸ”¥ é«˜"
        elif score >= 40:
            return "âš ï¸ ä¸­"
        else:
            return "ğŸ“„ ä½"
    
    def format_stock_section(self, stocks_data: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨éƒ¨åˆ†"""
        if not stocks_data:
            return "ğŸ“ˆ ä»Šæ—¥è‚¡ç¥¨\næš‚æ— æ•°æ®\n"
        
        section = "ğŸ“ˆ ä»Šæ—¥è‚¡ç¥¨\n"
        section += "=" * 30 + "\n"
        
        for stock in stocks_data:
            name = stock.get("name", "æœªçŸ¥")
            symbol = stock.get("symbol", "")
            price = stock.get("price", 0)
            change = stock.get("change", 0)
            change_percent = stock.get("change_percent", 0)
            currency = stock.get("currency", "")
            
            # ç¡®å®šè¡¨æƒ…ç¬¦å·
            if change_percent > 3:
                emoji = "ğŸš€"
            elif change_percent > 0:
                emoji = "ğŸ“ˆ"
            elif change_percent < -3:
                emoji = "ğŸ“‰"
            else:
                emoji = "â¡ï¸"
            
            section += f"{emoji} {name} ({symbol})\n"
            section += f"  ä»·æ ¼: {price:.2f} {currency}\n"
            section += f"  æ¶¨è·Œ: {change:+.2f} ({change_percent:+.2f}%)\n\n"
        
        return section
    
    def format_news_section(self, articles: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ–°é—»éƒ¨åˆ†"""
        if not articles:
            return "ğŸ“° ä»Šæ—¥æ–°é—»\næš‚æ— æ–°æ–‡ç« \n"
        
        section = "ğŸ“° ä»Šæ—¥æ–°é—»\n"
        section += "=" * 30 + "\n"
        
        for i, article in enumerate(articles[:5], 1):  # é™åˆ¶5æ¡
            title = article.get("title", "æ— æ ‡é¢˜")
            url = article.get("url", "")
            source = article.get("source", "æœªçŸ¥æ¥æº")
            
            # ç”Ÿæˆæ‘˜è¦
            description = article.get("description", "")
            summary = self.generate_summary(description)
            
            # è®¡ç®—é‡è¦æ€§
            importance_score = self.calculate_importance_score(article)
            importance_level = self.get_importance_level(importance_score)
            
            section += f"{i}. {title}\n"
            section += f"   æ¥æº: {source}\n"
            section += f"   é‡è¦æ€§: {importance_level}\n"
            section += f"   æ‘˜è¦: {summary}\n"
            
            if url:
                section += f"   é“¾æ¥: {url}\n"
            
            section += "\n"
        
        return section
    
    def generate_full_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        now = datetime.now()
        
        report = f"ğŸ“Š æ™ºèƒ½æ–°é—»æ¨é€æŠ¥å‘Š\n"
        report += f"æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += "=" * 40 + "\n\n"
        
        # è·å–è‚¡ç¥¨æ•°æ®
        stocks_data = self.get_all_stocks_data()
        report += self.format_stock_section(stocks_data)
        
        # è·å–æ–°é—»
        all_articles = self.fetch_all_news()
        new_articles = self.filter_new_articles(all_articles)
        report += self.format_news_section(new_articles)
        
        # ç»Ÿè®¡ä¿¡æ¯
        report += "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n"
        report += "=" * 30 + "\n"
        report += f"â€¢ è‚¡ç¥¨ç›‘æ§: {len(stocks_data)} åª\n"
        report += f"â€¢ æ–°é—»æº: {len(self.news_sources)} ä¸ª\n"
        report += f"â€¢ æ–°æ–‡ç« : {len(new_articles)} ç¯‡\n"
        report += f"â€¢ æ•°æ®åº“è®°å½•: {self.db.get_stats().get('total_articles', 0)} æ¡\n"
        
        report += "\nâ° ä¸‹æ¬¡æ¨é€: æ•´ç‚¹æ—¶åˆ»\n"
        report += "ğŸ”” ç³»ç»ŸçŠ¶æ€: è¿è¡Œæ­£å¸¸\n"
        
        return report
    
    def run(self) -> bool:
        """è¿è¡Œæ¨é€å™¨"""
        try:
            self.logger.info("å¼€å§‹ç”Ÿæˆæ¨é€æŠ¥å‘Š")
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_full_report()
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            report_file = f"./logs/push_report_{timestamp}.txt"
            
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(report)
            
            self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            self.logger.info(f"æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")
            
            # æ ‡è®°æ–‡ç« ä¸ºå·²æ¨é€
            all_articles = self.fetch_all_news()
            for article in all_articles:
                if not self.db.is_article_pushed(article["title"], article["url"]):
                    self.db.mark_article_pushed(
                        article["title"], 
                        article["url"], 
                        article.get("source", "æœªçŸ¥")
                    )
            
            # æ¸…ç†æ—§è®°å½•
            deleted_count = self.db.cleanup_old_records(days=7)
            if deleted_count > 0:
                self.logger.info(f"æ¸…ç†äº† {deleted_count} æ¡æ—§è®°å½•")
            
            self.logger.info("æ¨é€å™¨è¿è¡Œå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨é€å™¨è¿è¡Œå¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–ç‰ˆæ–°é—»è‚¡ç¥¨æ¨é€ç³»ç»Ÿ")
    print("=" * 50)
    
    pusher = NewsStockPusherOptimized()
    
    # è¿è¡Œæ¨é€å™¨
    success = pusher.run()
    
    if success:
        print("âœ… æ¨é€å™¨è¿è¡ŒæˆåŠŸ")
        return 0
    else:
        print("âŒ æ¨é€å™¨è¿è¡Œå¤±è´¥")
        return 1

if __name__ == "__main__":
    sys.exit(main())
