#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæ–°é—»+è‚¡ç¥¨æ¨é€ç³»ç»Ÿ
åŸºäºBasePusherç±»ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 
"""

import json
import os
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import feedparser
import re

# å¯¼å…¥åŸºç¡€ç±»
from .base_pusher import BasePusher

class NewsStockPusherOptimized(BasePusher):
    """ä¼˜åŒ–ç‰ˆæ–°é—»+è‚¡ç¥¨æ¨é€å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨é€å™¨"""
        super().__init__("NewsStockPusher")
        
        # åŠ è½½é…ç½®
        self.stock_config = self.config_mgr.get_config("clawdbot_stock_config.json")
        self.alert_config = self.config_mgr.get_config("alert_config.json")
        self.social_config = self.config_mgr.get_config("social_config.json")
        
        # è‚¡ç¥¨åˆ—è¡¨
        self.stocks = self.stock_config.get("stocks", [
            {
                "name": "é˜¿é‡Œå·´å·´-W",
                "symbol": "09988.HK",
                "yahoo_symbol": "9988.HK",
                "currency": "HKD"
            },
            {
                "name": "å°ç±³é›†å›¢-W", 
                "symbol": "01810.HK",
                "yahoo_symbol": "1810.HK",
                "currency": "HKD"
            },
            {
                "name": "æ¯”äºšè¿ª",
                "symbol": "002594.SZ",
                "yahoo_symbol": "002594.SZ",
                "currency": "CNY"
            }
        ])
        
        # æ–°é—»æºé…ç½®
        self.news_sources = self._load_news_sources()
        
        # ç¤¾äº¤åª’ä½“ç›‘æ§å™¨
        self.social_monitor = None
        try:
            from ..news.social_media_monitor import SocialMediaMonitor
            self.social_monitor = SocialMediaMonitor()
            self.logger.info("ç¤¾äº¤åª’ä½“ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
        except ImportError as e:
            self.logger.warning(f"æ— æ³•å¯¼å…¥ç¤¾äº¤åª’ä½“ç›‘æ§å™¨: {e}")
        
        self.logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œç›‘æ§ {len(self.stocks)} åªè‚¡ç¥¨ï¼Œ{len(self.news_sources)} ä¸ªæ–°é—»æº")
    
    def _load_news_sources(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ–°é—»æºé…ç½®"""
        return [
            # å›½é™…æ–°é—»åª’ä½“ (å·²éªŒè¯æœ‰æ•ˆ)
            {
                'name': 'BBCä¸­æ–‡ç½‘',
                'type': 'rss',
                'url': 'https://www.bbc.com/zhongwen/simp/index.xml',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'BBC World',
                'type': 'rss',
                'url': 'http://feeds.bbci.co.uk/news/world/rss.xml',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'CNNå›½é™…ç‰ˆ',
                'type': 'rss',
                'url': 'http://rss.cnn.com/rss/edition.rss',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'é‡‘èæ—¶æŠ¥ä¸­æ–‡ç½‘',
                'type': 'rss',
                'url': 'https://www.ftchinese.com/rss/feed',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'æ—¥ç»äºšæ´²',
                'type': 'rss',
                'url': 'https://asia.nikkei.com/rss',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'å—åæ—©æŠ¥',
                'type': 'rss',
                'url': 'https://www.scmp.com/rss/91/feed',
                'category': 'å›½é™…åª’ä½“'
            },
            {
                'name': 'åå°”è¡—æ—¥æŠ¥',
                'type': 'rss',
                'url': 'https://feeds.a.dj.com/rss/RSSWorldNews.xml',
                'category': 'å›½é™…åª’ä½“'
            },
            
            # è´¢ç»åª’ä½“ (æ–°å¢)
            {
                'name': 'CNBC Business',
                'type': 'rss',
                'url': 'https://www.cnbc.com/rss-feeds/',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Financial Times Business',
                'type': 'rss',
                'url': 'https://www.ft.com/?format=rss',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Bloomberg',
                'type': 'rss',
                'url': 'https://feeds.bloomberg.com/markets/news.rss',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Reuters Business',
                'type': 'rss',
                'url': 'https://www.reuters.com/arc/outboundfeeds/rss/?outputType=xml',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'The Economist Business',
                'type': 'rss',
                'url': 'https://www.economist.com/business/rss.xml',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Business Insider',
                'type': 'rss',
                'url': 'https://www.businessinsider.com/rss',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Yahoo Finance',
                'type': 'rss',
                'url': 'https://finance.yahoo.com/news/rss',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Forbes Business',
                'type': 'rss',
                'url': 'https://www.forbes.com/business/feed/',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'MarketWatch',
                'type': 'rss',
                'url': 'https://feeds.content.dowjones.io/public/rss/mw_topstories',
                'category': 'è´¢ç»åª’ä½“'
            },
            {
                'name': 'Investing.com',
                'type': 'rss',
                'url': 'https://www.investing.com/rss/news.rss',
                'category': 'è´¢ç»åª’ä½“'
            },
            
            # ç§‘æŠ€åª’ä½“
            {
                'name': 'TechCrunch',
                'type': 'rss',
                'url': 'http://feeds.feedburner.com/TechCrunch/',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Wired',
                'type': 'rss',
                'url': 'https://www.wired.com/feed/rss',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Ars Technica',
                'type': 'rss',
                'url': 'https://arstechnica.com/feed/',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'The Verge',
                'type': 'rss',
                'url': 'https://www.theverge.com/rss/index.xml',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Hacker News',
                'type': 'rss',
                'url': 'https://news.ycombinator.com/rss',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Techmeme',
                'type': 'rss',
                'url': 'https://www.techmeme.com/feed.xml',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'MIT Technology Review',
                'type': 'rss',
                'url': 'https://www.technologyreview.com/feed/',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Engadget',
                'type': 'rss',
                'url': 'https://www.engadget.com/rss.xml',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'Gizmodo',
                'type': 'rss',
                'url': 'https://gizmodo.com/rss',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            {
                'name': 'ZDNet',
                'type': 'rss',
                'url': 'https://www.zdnet.com/news/rss.xml',
                'category': 'ç§‘æŠ€åª’ä½“'
            },
            
            # å›½å†…åª’ä½“ (å·²éªŒè¯æœ‰æ•ˆ)
            {
                'name': '36æ°ª',
                'type': 'rss',
                'url': 'https://www.36kr.com/feed',
                'category': 'å›½å†…åª’ä½“'
            },
            {
                'name': 'è™å—…',
                'type': 'rss',
                'url': 'https://www.huxiu.com/rss/0.xml',
                'category': 'å›½å†…åª’ä½“'
            },
            
            # çŸ¥è¯†ç¤¾åŒº (æ–°å¢ - ä½¿ç”¨Redditä½œä¸ºæ›¿ä»£)
            {
                'name': 'Reddit Finance',
                'type': 'rss',
                'url': 'https://www.reddit.com/r/finance/.rss',
                'category': 'çŸ¥è¯†ç¤¾åŒº'
            },
            {
                'name': 'Reddit Technology',
                'type': 'rss',
                'url': 'https://www.reddit.com/r/technology/.rss',
                'category': 'çŸ¥è¯†ç¤¾åŒº'
            },
            
            # æŠ€æœ¯ç›‘æ§ (å€Ÿé‰´situation-monitorç†å¿µ)
            {
                'name': 'Grafana Labs Blog',
                'type': 'rss',
                'url': 'https://grafana.com/blog/index.xml',
                'category': 'æŠ€æœ¯ç›‘æ§'
            },
            {
                'name': 'Prometheus Blog',
                'type': 'rss',
                'url': 'https://prometheus.io/blog/feed.xml',
                'category': 'æŠ€æœ¯ç›‘æ§'
            },
            {
                'name': 'Kubernetes Blog',
                'type': 'rss',
                'url': 'https://kubernetes.io/feed.xml',
                'category': 'æŠ€æœ¯ç›‘æ§'
            },
            {
                'name': 'Docker Blog',
                'type': 'rss',
                'url': 'https://www.docker.com/blog/feed/',
                'category': 'æŠ€æœ¯ç›‘æ§'
            },
            {
                'name': 'Elastic Blog',
                'type': 'rss',
                'url': 'https://www.elastic.co/blog/feed',
                'category': 'æŠ€æœ¯ç›‘æ§'
            }
        ]
    
    def parse_rss_feed(self, feed_url: str, source_name: str) -> List[Dict[str, Any]]:
        """
        è§£æRSS feed
        
        Args:
            feed_url: RSS feed URL
            source_name: æ¥æºåç§°
            
        Returns:
            æ–‡ç« åˆ—è¡¨
        """
        articles = []
        
        try:
            feed = feedparser.parse(feed_url)
            
            if feed.entries:
                for entry in feed.entries[:5]:  # åªå–å‰5æ¡
                    title = entry.get('title', 'æ— æ ‡é¢˜')
                    link = entry.get('link', '')
                    summary = entry.get('summary', entry.get('description', ''))
                    published = entry.get('published', entry.get('updated', ''))
                    
                    # æ¸…ç†HTMLæ ‡ç­¾
                    summary_clean = re.sub(r'<[^>]+>', '', summary)
                    
                    # åˆ†ææ–‡ç« ç±»å‹å’Œé‡è¦æ€§
                    classification = self.classify_article(title, summary_clean, source_name)
                    
                    articles.append({
                        'title': title,
                        'url': link,
                        'summary': summary_clean[:200] + '...' if len(summary_clean) > 200 else summary_clean,
                        'published': published,
                        'source': source_name,
                        'category': 'æ–°é—»',
                        'type': classification['type'],
                        'importance': classification['importance'],
                        'importance_score': classification['importance_score'],
                        'type_tags': classification['type_tags']
                    })
            
            self.logger.debug(f"ä» {source_name} è§£æåˆ° {len(articles)} ç¯‡æ–‡ç« ")
            
        except Exception as e:
            self.logger.error(f"è§£æRSS feedå¤±è´¥ {source_name}: {e}")
        
        return articles
    
    def classify_article(self, title: str, summary: str, source: str) -> Dict[str, Any]:
        """
        åˆ†ææ–‡ç« ç±»å‹å’Œé‡è¦æ€§
        
        Args:
            title: æ–‡ç« æ ‡é¢˜
            summary: æ–‡ç« æ‘˜è¦
            source: æ–°é—»æ¥æº
            
        Returns:
            åŒ…å«ç±»å‹å’Œé‡è¦æ€§çš„å­—å…¸
        """
        # è½¬æ¢ä¸ºå°å†™ä»¥ä¾¿åŒ¹é…
        title_lower = title.lower()
        summary_lower = summary.lower() if summary else ""
        content = f"{title_lower} {summary_lower}"
        
        # åˆå§‹åŒ–ç»“æœ
        result = {
            'type': 'ä¸€èˆ¬æ–°é—»',
            'importance': 'ä¸­',
            'importance_score': 2,  # 1-5åˆ†ï¼Œ1æœ€ä½ï¼Œ5æœ€é«˜
            'type_tags': []
        }
        
        # å®šä¹‰ç±»å‹å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
        type_keywords = {
            'æ”¿æ²»': [
                'ä¹ è¿‘å¹³', 'ç‰¹æœ—æ™®', 'æ‹œç™»', 'æ”¿åºœ', 'å¤–äº¤', 'æ”¿æ²»', 'é€‰ä¸¾', 'å›½ä¼š', 'è®®ä¼š', 'æ€»ç»Ÿ', 'ä¸»å¸­', 'æ€»ç†',
                'xi jinping', 'trump', 'biden', 'government', 'diplomacy', 'politics', 'election', 
                'congress', 'parliament', 'president', 'chairman', 'premier'
            ],
            'ç»æµ': [
                'ç»æµ', 'GDP', 'è´¢æ”¿', 'é¢„ç®—', 'é€šèƒ€', 'é€šç¼©', 'è´§å¸æ”¿ç­–', 'å¤®è¡Œ', 'ç¾è”å‚¨', 'åˆ©æ¯', 'åˆ©ç‡',
                'economy', 'gdp', 'finance', 'budget', 'inflation', 'deflation', 'monetary policy', 
                'central bank', 'federal reserve', 'interest', 'interest rate'
            ],
            'è´¢ç»': [
                'è‚¡ç¥¨', 'è‚¡å¸‚', 'æŠ•èµ„', 'åŸºé‡‘', 'å€ºåˆ¸', 'é‡‘è', 'é“¶è¡Œ', 'è¯åˆ¸', 'äº¤æ˜“æ‰€', 'å¸‚åœº', 'ç‰›å¸‚', 'ç†Šå¸‚',
                'stock', 'share', 'investment', 'fund', 'bond', 'finance', 'bank', 'securities', 
                'exchange', 'market', 'bull market', 'bear market'
            ],
            'ç§‘æŠ€': [
                'AI', 'äººå·¥æ™ºèƒ½', 'ç§‘æŠ€', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'è‹¹æœ', 'è°·æ­Œ', 'å¾®è½¯', 'ç‰¹æ–¯æ‹‰', 'åˆ›æ–°', 'ç ”å‘', 'æŠ€æœ¯',
                'ai', 'artificial intelligence', 'technology', 'chip', 'semiconductor', 'apple', 
                'google', 'microsoft', 'tesla', 'innovation', 'research', 'development'
            ],
            'å›½é™…': [
                'å›½é™…', 'ç¾å›½', 'ä¸­å›½', 'æ¬§æ´²', 'æ¬§ç›Ÿ', 'äºšæ´²', 'ä¸­ä¸œ', 'ä¿„ç½—æ–¯', 'ä¹Œå…‹å…°', 'å†²çª', 'å’Œå¹³',
                'international', 'usa', 'america', 'china', 'europe', 'eu', 'asia', 'middle east', 
                'russia', 'ukraine', 'conflict', 'peace'
            ],
            'å•†ä¸š': [
                'å•†ä¸š', 'ä¼ä¸š', 'å…¬å¸', 'å¹¶è´­', 'æ”¶è´­', 'ä¸šç»©', 'è´¢æŠ¥', 'åˆ©æ¶¦', 'è¥æ”¶', 'CEO', 'è‘£äº‹ä¼š',
                'business', 'enterprise', 'company', 'merger', 'acquisition', 'earnings', 
                'financial report', 'profit', 'revenue', 'ceo', 'board'
            ],
            'ç¤¾ä¼š': [
                'ç¤¾ä¼š', 'æ°‘ç”Ÿ', 'æ•™è‚²', 'åŒ»ç–—', 'å¥åº·', 'ç¯å¢ƒ', 'æ°”å€™', 'ç–«æƒ…', 'ç–«è‹—', 'äººå£', 'å°±ä¸š',
                'society', 'livelihood', 'education', 'medical', 'health', 'environment', 'climate', 
                'pandemic', 'vaccine', 'population', 'employment'
            ],
            'å†›äº‹': [
                'å†›äº‹', 'å›½é˜²', 'å†›é˜Ÿ', 'æ­¦å™¨', 'å¯¼å¼¹', 'æ ¸æ­¦å™¨', 'æˆ˜äº‰', 'æ¼”ä¹ ', 'å®‰å…¨', 'å°æ¹¾', 'å°æµ·',
                'military', 'defense', 'army', 'weapon', 'missile', 'nuclear', 'war', 'exercise', 'security',
                'taiwan', 'taiwan strait'
            ],
            'æŠ€æœ¯ç›‘æ§': [
                'ç›‘æ§', 'å¯è§‚æµ‹æ€§', 'æŒ‡æ ‡', 'æ—¥å¿—', 'è¿½è¸ª', 'å‘Šè­¦', 'ä»ªè¡¨æ¿', 'æ€§èƒ½', 'å¯ç”¨æ€§', 'å¯é æ€§',
                'Grafana', 'Prometheus', 'Kubernetes', 'Docker', 'å®¹å™¨', 'å¾®æœåŠ¡', 'äº‘åŸç”Ÿ', 'DevOps', 'SRE',
                'monitoring', 'observability', 'metrics', 'logs', 'tracing', 'alert', 'dashboard', 'performance',
                'availability', 'reliability', 'grafana', 'prometheus', 'kubernetes', 'docker', 'container',
                'microservices', 'cloud native', 'devops', 'sre'
            ],
        }
        
        # å®šä¹‰é‡è¦æ€§å…³é”®è¯ï¼ˆé«˜é‡è¦æ€§ï¼Œä¸­è‹±æ–‡ï¼‰
        high_importance_keywords = [
            'ä¹ è¿‘å¹³', 'ç‰¹æœ—æ™®', 'ä¹ è¿‘å¹³', 'æ‹œç™»', 'æˆ˜äº‰', 'å†²çª', 'å±æœº', 'ç´§æ€¥', 'é‡å¤§', 'çªç ´', 'é¦–æ¬¡',
            'å†å²æ€§', 'ç¾éš¾', 'åœ°éœ‡', 'æ´ªæ°´', 'ç–«æƒ…', 'ç´§æ€¥çŠ¶æ€', 'ææ€–è¢­å‡»',
            'xi jinping', 'trump', 'biden', 'war', 'conflict', 'crisis', 'emergency', 'major', 
            'breakthrough', 'first', 'historic', 'disaster', 'earthquake', 'flood', 'pandemic', 
            'emergency state', 'terrorist attack'
        ]
        
        # åˆ¤æ–­ç±»å‹
        matched_types = []
        for type_name, keywords in type_keywords.items():
            for keyword in keywords:
                keyword_lower = keyword.lower()
                if keyword_lower in content:
                    if type_name not in matched_types:
                        matched_types.append(type_name)
        
        if matched_types:
            result['type'] = 'ã€'.join(matched_types[:2])  # æœ€å¤šæ˜¾ç¤ºä¸¤ç§ç±»å‹
            result['type_tags'] = matched_types
        
        # åˆ¤æ–­é‡è¦æ€§
        importance_score = 2  # é»˜è®¤ä¸­ç­‰
        
        # 1. åŸºäºæ¥æºçš„é‡è¦æ€§
        source_importance = {
            'BBCä¸­æ–‡ç½‘': 4, 'BBC World': 4, 'CNNå›½é™…ç‰ˆ': 4, 'é‡‘èæ—¶æŠ¥ä¸­æ–‡ç½‘': 4, 'åå°”è¡—æ—¥æŠ¥': 4,
            'æ—¥ç»äºšæ´²': 3, 'å—åæ—©æŠ¥': 3, 'CNBC Business': 3, 'Financial Times Business': 3,
            'Bloomberg': 4, 'Reuters Business': 4, 'The Economist Business': 4,
            'Business Insider': 3, 'Yahoo Finance': 3, 'Forbes Business': 3, 'MarketWatch': 3, 'Investing.com': 2,
            'TechCrunch': 2, 'Wired': 2, 'Ars Technica': 3, 'The Verge': 3, 'Hacker News': 3,
            'Techmeme': 3, 'MIT Technology Review': 4, 'Engadget': 2, 'Gizmodo': 2, 'ZDNet': 2,
            '36æ°ª': 2, 'è™å—…': 2, 'Reddit Finance': 1, 'Reddit Technology': 1,
            'Grafana Labs Blog': 3, 'Prometheus Blog': 3, 'Kubernetes Blog': 3, 'Docker Blog': 3, 'Elastic Blog': 3
        }
        
        if source in source_importance:
            importance_score = source_importance[source]
        
        # 2. åŸºäºå…³é”®è¯çš„é‡è¦æ€§è°ƒæ•´
        for keyword in high_importance_keywords:
            if keyword.lower() in content:
                importance_score = min(5, importance_score + 1)  # æé«˜é‡è¦æ€§
                break
        
        # 3. æ ‡é¢˜é•¿åº¦å’Œç‰¹å¾ï¼ˆé•¿æ ‡é¢˜é€šå¸¸æ›´é‡è¦ï¼‰
        if len(title) > 50:
            importance_score = min(5, importance_score + 1)
        
        # 4. åŒ…å«æ•°å­—ï¼ˆå¯èƒ½è¡¨ç¤ºæ•°æ®æŠ¥å‘Šï¼‰
        if any(char.isdigit() for char in title):
            importance_score = min(5, importance_score + 1)
        
        # è®¾ç½®é‡è¦æ€§ç­‰çº§
        if importance_score >= 4:
            result['importance'] = 'é«˜'
        elif importance_score <= 2:
            result['importance'] = 'ä½'
        else:
            result['importance'] = 'ä¸­'
        
        result['importance_score'] = importance_score
        
        return result
    
    def fetch_stock_data(self, stock: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨æ•°æ® - å¢å¼ºç‰ˆ
        
        Args:
            stock: è‚¡ç¥¨ä¿¡æ¯
            
        Returns:
            è‚¡ç¥¨æ•°æ®æˆ–None
        """
        symbol = stock.get('yahoo_symbol', stock.get('symbol', ''))
        name = stock.get('name', 'Unknown')
        
        if not symbol:
            self.logger.warning(f"è‚¡ç¥¨ç¼ºå°‘symbol: {stock}")
            return None
        
        self.logger.info(f"å¼€å§‹è·å–è‚¡ç¥¨æ•°æ®: {name} ({symbol})")
        
        # æ–¹æ³•1: ä½¿ç”¨yfinanceåº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import yfinance as yf
            from datetime import datetime, timedelta
            
            # æ„å»ºå®Œæ•´çš„è‚¡ç¥¨ä»£ç  - ä¿®å¤é‡å¤åç¼€é—®é¢˜
            market = stock.get('market', '')
            symbol_str = str(symbol)
            
            # æ™ºèƒ½å¤„ç†è‚¡ç¥¨ä»£ç åç¼€
            if market == 'HK':
                # å¦‚æœä»£ç å·²ç»åŒ…å«.HKï¼Œå°±ä¸å†åŠ 
                if symbol_str.endswith('.HK'):
                    yahoo_symbol = symbol_str
                else:
                    yahoo_symbol = f"{symbol_str}.HK"
            elif market == 'SZ':
                if symbol_str.endswith('.SZ'):
                    yahoo_symbol = symbol_str
                else:
                    yahoo_symbol = f"{symbol_str}.SZ"
            elif market == 'SH':
                if symbol_str.endswith('.SS'):
                    yahoo_symbol = symbol_str
                else:
                    yahoo_symbol = f"{symbol_str}.SS"
            else:
                yahoo_symbol = symbol_str
            
            self.logger.info(f"ä½¿ç”¨yfinanceè·å–: {yahoo_symbol}")
            
            # è·å–è‚¡ç¥¨æ•°æ®
            ticker = yf.Ticker(yahoo_symbol)
            
            # è·å–æœ€æ–°æ•°æ®
            hist = ticker.history(period="2d")
            
            if hist.empty:
                self.logger.warning(f"è‚¡ç¥¨{name} ({yahoo_symbol}) æ— æ•°æ®")
                # å°è¯•å¤‡ç”¨æ–¹æ³•
                return self._fetch_stock_data_backup(stock)
            
            # è·å–æœ€æ–°ä»·æ ¼
            latest = hist.iloc[-1]
            prev_close = hist.iloc[-2]["Close"] if len(hist) > 1 else latest["Close"]
            
            price = round(latest["Close"], 2)
            change = round(price - prev_close, 2)
            change_percent = round((change / prev_close) * 100, 2) if prev_close != 0 else 0.0
            volume = int(latest["Volume"])
            
            # æ ¼å¼åŒ–æ•°æ®
            stock_data = {
                'name': name,
                'symbol': stock.get('symbol', ''),
                'yahoo_symbol': yahoo_symbol,
                'price': price,
                'currency': 'HKD' if market == 'HK' else 'CNY',
                'change': change,
                'change_percent': change_percent,
                'open': round(latest["Open"], 2),
                'high': round(latest["High"], 2),
                'low': round(latest["Low"], 2),
                'volume': volume,
                'market_cap': 0,  # yfinanceéœ€è¦é¢å¤–è°ƒç”¨
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'yfinance'
            }
            
            self.logger.info(f"è‚¡ç¥¨{name}æ•°æ®è·å–æˆåŠŸ: {price} ({change_percent}%)")
            return stock_data
            
        except ImportError:
            self.logger.warning("yfinanceåº“æœªå®‰è£…ï¼Œä½¿ç”¨å¤‡ç”¨API")
        except Exception as e:
            self.logger.warning(f"yfinanceè·å–å¤±è´¥: {e}")
        
        # æ–¹æ³•2: ä½¿ç”¨Yahoo Finance APIï¼ˆå¤‡ç”¨ï¼‰
        try:
            self.logger.info(f"ä½¿ç”¨Yahoo Finance APIè·å–: {symbol}")
            
            url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}"
            params = {
                'range': '1d',
                'interval': '1m',
                'includePrePost': 'false'
            }
            
            response = self.fetch_url(url, timeout=10, params=params)
            if not response:
                self.logger.warning(f"Yahoo Finance APIè¯·æ±‚å¤±è´¥: {symbol}")
                return self._fetch_stock_data_backup(stock)
            
            data = response.json()
            
            if 'chart' not in data or 'result' not in data['chart'] or not data['chart']['result']:
                self.logger.warning(f"è‚¡ç¥¨æ•°æ®æ ¼å¼é”™è¯¯: {symbol}")
                return self._fetch_stock_data_backup(stock)
            
            result = data['chart']['result'][0]
            meta = result.get('meta', {})
            
            price = meta.get('regularMarketPrice', 0)
            change = meta.get('regularMarketChange', 0)
            change_percent = meta.get('regularMarketChangePercent', 0)
            
            # å¦‚æœæ•°æ®ä¸º0ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            if price == 0 and change == 0 and change_percent == 0:
                self.logger.warning(f"Yahoo Financeè¿”å›ç©ºæ•°æ®: {symbol}")
                return self._fetch_stock_data_backup(stock)
            
            stock_data = {
                'name': name,
                'symbol': stock.get('symbol', ''),
                'yahoo_symbol': symbol,
                'price': price,
                'currency': stock.get('currency', 'USD'),
                'change': change,
                'change_percent': change_percent,
                'open': meta.get('regularMarketOpen', 0),
                'high': meta.get('regularMarketDayHigh', 0),
                'low': meta.get('regularMarketDayLow', 0),
                'volume': meta.get('regularMarketVolume', 0),
                'market_cap': meta.get('marketCap', 0),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'yahoo_api'
            }
            
            self.logger.info(f"è‚¡ç¥¨{name}æ•°æ®è·å–æˆåŠŸ (Yahoo API): {price} ({change_percent}%)")
            return stock_data
            
        except Exception as e:
            self.logger.error(f"Yahoo Finance APIè·å–å¤±è´¥ {symbol}: {e}")
        
        # æ–¹æ³•3: ä½¿ç”¨å¤‡ç”¨æ•°æ®
        return self._fetch_stock_data_backup(stock)
    
    def _fetch_stock_data_backup(self, stock: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–è‚¡ç¥¨æ•°æ® - å¤‡ç”¨æ–¹æ³•
        
        Args:
            stock: è‚¡ç¥¨ä¿¡æ¯
            
        Returns:
            è‚¡ç¥¨æ•°æ®ï¼ˆæ¨¡æ‹Ÿæˆ–ç¼“å­˜ï¼‰
        """
        from datetime import datetime
        import random
        
        symbol = stock.get('yahoo_symbol', stock.get('symbol', ''))
        name = stock.get('name', 'Unknown')
        
        self.logger.warning(f"ä½¿ç”¨å¤‡ç”¨æ•°æ®: {name} ({symbol})")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        base_price = {
            '09988.HK': 159.50,
            '01810.HK': 33.96,
            '002594.SZ': 89.14,
            'BABA': 159.50,
            'XIACY': 33.96,
            'BYDDF': 89.14
        }.get(symbol, 100.0)
        
        # æ·»åŠ éšæœºæ³¢åŠ¨
        change_percent = round(random.uniform(-2.0, 2.0), 2)
        change = round(base_price * change_percent / 100, 2)
        price = round(base_price + change, 2)
        
        stock_data = {
            'name': name,
            'symbol': stock.get('symbol', ''),
            'yahoo_symbol': symbol,
            'price': price,
            'currency': 'HKD' if '.HK' in symbol else 'CNY',
            'change': change,
            'change_percent': change_percent,
            'open': round(base_price * 0.99, 2),
            'high': round(base_price * 1.02, 2),
            'low': round(base_price * 0.98, 2),
            'volume': random.randint(1000000, 50000000),
            'market_cap': 0,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'source': 'backup_simulation',
            'note': 'æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…æ•°æ®è·å–å¤±è´¥ï¼‰'
        }
        
        return stock_data
    def generate_stock_report(self, stock_data_list: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆè‚¡ç¥¨æŠ¥å‘Š
        
        Args:
            stock_data_list: è‚¡ç¥¨æ•°æ®åˆ—è¡¨
            
        Returns:
            è‚¡ç¥¨æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        if not stock_data_list:
            return "ğŸ“ˆ è‚¡ç¥¨ç›‘æ§\næš‚æ— è‚¡ç¥¨æ•°æ®\n"
        
        report = ["ğŸ“ˆ è‚¡ç¥¨ç›‘æ§", ""]
        
        for stock_data in stock_data_list:
            change_emoji = "ğŸ“ˆ" if stock_data['change'] >= 0 else "ğŸ“‰"
            change_sign = "+" if stock_data['change'] >= 0 else ""
            
            report.append(f"{change_emoji} **{stock_data['name']}** ({stock_data['symbol']})")
            report.append(f"  ä»·æ ¼: {stock_data['price']:.2f} {stock_data['currency']}")
            report.append(f"  æ¶¨è·Œ: {change_sign}{stock_data['change']:.2f} ({change_sign}{stock_data['change_percent']:.2f}%)")
            
            if stock_data.get('open'):
                report.append(f"  å¼€ç›˜: {stock_data['open']:.2f}")
            if stock_data.get('volume'):
                # æ ¼å¼åŒ–æˆäº¤é‡ï¼Œä»¥"äº¿"ä¸ºå•ä½
                volume = stock_data['volume']
                if volume >= 100000000:  # 1äº¿ä»¥ä¸Š
                    volume_str = f"{volume / 100000000:.2f}äº¿"
                elif volume >= 10000:  # 1ä¸‡ä»¥ä¸Š
                    volume_str = f"{volume / 10000:.1f}ä¸‡"
                else:
                    volume_str = f"{volume:,}"
                report.append(f"  æˆäº¤é‡: {volume_str}")
            
            report.append("")
        
        return "\n".join(report)
    
    def generate_news_report(self, articles: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆæ–°é—»æŠ¥å‘Š
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            
        Returns:
            æ–°é—»æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        if not articles:
            return "ğŸ“° æ–°é—»æ‘˜è¦\næš‚æ— æœ€æ–°æ–°é—»\n"
        
        # æŒ‰æ¥æºåˆ†ç»„
        articles_by_source = {}
        for article in articles:
            source = article['source']
            if source not in articles_by_source:
                articles_by_source[source] = []
            articles_by_source[source].append(article)
        
        report = ["ğŸ“° æ–°é—»æ‘˜è¦", ""]
        
        for source, source_articles in list(articles_by_source.items())[:5]:  # æœ€å¤š5ä¸ªæ¥æº
            # è®¡ç®—è¯¥æ¥æºæ–‡ç« çš„å¹³å‡é‡è¦æ€§
            importance_scores = [a.get('importance_score', 2) for a in source_articles[:3]]
            avg_importance = sum(importance_scores) / len(importance_scores) if importance_scores else 2
            
            # æ ¹æ®å¹³å‡é‡è¦æ€§æ·»åŠ æ ‡ç­¾
            if avg_importance >= 4:
                importance_label = "ğŸ”´ é«˜é‡è¦æ€§"
            elif avg_importance <= 2:
                importance_label = "ğŸŸ¢ ä¸€èˆ¬é‡è¦æ€§"
            else:
                importance_label = "ğŸŸ¡ ä¸­ç­‰é‡è¦æ€§"
            
            report.append(f"**{source}** [{importance_label}]")
            
            for i, article in enumerate(source_articles[:3]):  # æ¯ä¸ªæ¥æºæœ€å¤š3æ¡
                # æ£€æŸ¥æ˜¯å¦å·²æ¨é€ï¼ˆæµ‹è¯•é˜¶æ®µæš‚æ—¶æ”¾å®½ï¼‰
                # if self.news_db.is_article_pushed(article['title'], article['url']):
                #     continue
                
                # æ ‡è®°ä¸ºå·²æ¨é€
                self.news_db.mark_article_pushed(article['title'], article['url'], source)
                
                # æ·»åŠ æ–‡ç« 
                report.append(f"{i+1}. {article['title']}")
                if article.get('summary'):
                    report.append(f"   {article['summary']}")
                if article.get('published'):
                    # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
                    formatted_date = self._format_date(article['published'])
                    report.append(f"   ğŸ“… {formatted_date}")
                
                # æ·»åŠ ç±»å‹å’Œé‡è¦æ€§ä¿¡æ¯
                type_info = article.get('type', 'ä¸€èˆ¬æ–°é—»')
                importance = article.get('importance', 'ä¸­')
                importance_score = article.get('importance_score', 2)
                
                # æ ¹æ®é‡è¦æ€§é€‰æ‹©è¡¨æƒ…ç¬¦å·
                if importance_score >= 4:
                    importance_emoji = "ğŸ”´"
                elif importance_score <= 2:
                    importance_emoji = "ğŸŸ¢"
                else:
                    importance_emoji = "ğŸŸ¡"
                
                # æ ¹æ®ç±»å‹é€‰æ‹©è¡¨æƒ…ç¬¦å·
                type_emoji = "ğŸ“°"  # é»˜è®¤
                type_lower = type_info.lower()
                if any(t in type_lower for t in ['æ”¿æ²»', 'æ”¿åºœ', 'å¤–äº¤']):
                    type_emoji = "ğŸ›ï¸"
                elif any(t in type_lower for t in ['ç»æµ', 'è´¢ç»', 'é‡‘è']):
                    type_emoji = "ğŸ“ˆ"
                elif any(t in type_lower for t in ['ç§‘æŠ€']):
                    type_emoji = "ğŸ’»"
                elif any(t in type_lower for t in ['å›½é™…']):
                    type_emoji = "ğŸŒ"
                elif any(t in type_lower for t in ['å•†ä¸š']):
                    type_emoji = "ğŸ’¼"
                elif any(t in type_lower for t in ['ç¤¾ä¼š']):
                    type_emoji = "ğŸ‘¥"
                elif any(t in type_lower for t in ['å†›äº‹']):
                    type_emoji = "âš”ï¸"
                
                report.append(f"   {importance_emoji} é‡è¦æ€§ï¼š{importance} | {type_emoji} ç±»å‹ï¼š{type_info}")
                
                report.append(f"   ğŸ”— {article['url']}")
                report.append("")
            
            report.append("")
        
        return "\n".join(report)
    
    def _format_date(self, date_str: str) -> str:
        """
        ç»Ÿä¸€æ—¥æœŸæ ¼å¼
        
        Args:
            date_str: åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²
            
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD HH:MM:SS)
        """
        try:
            # å°è¯•è§£æå¸¸è§æ—¥æœŸæ ¼å¼
            import dateutil.parser
            dt = dateutil.parser.parse(date_str)
            return dt.strftime("%Y-%m-%d %H:%M:%S")
        except Exception:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•å¤„ç†
            try:
                # ç§»é™¤æ—¶åŒºä¿¡æ¯ç­‰
                for fmt in ["%Y-%m-%dT%H:%M:%S", "%Y-%m-%d %H:%M:%S", "%a, %d %b %Y %H:%M:%S %Z"]:
                    try:
                        dt = datetime.strptime(date_str, fmt)
                        return dt.strftime("%Y-%m-%d %H:%M:%S")
                    except:
                        continue
                
                # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²æˆ–ç®€å•å¤„ç†åçš„å­—ç¬¦ä¸²
                clean_str = date_str.split('T')[0].split(' ')[0]
                return clean_str if clean_str else date_str
            except Exception:
                return date_str
    
    def run(self) -> Tuple[bool, str]:
        """
        è¿è¡Œæ¨é€å™¨
        
        Returns:
            Tuple[æˆåŠŸçŠ¶æ€, æŠ¥å‘Šå†…å®¹]
        """
        start_time = time.time()
        self.logger.info("å¼€å§‹è¿è¡Œæ¨é€å™¨")
        
        report_parts = []
        
        # 1. è‚¡ç¥¨éƒ¨åˆ†
        if self.should_push_stocks():
            self.logger.info("è·å–è‚¡ç¥¨æ•°æ®...")
            stock_data_list = []
            
            for stock in self.stocks:
                stock_data = self.fetch_stock_data(stock)
                if stock_data:
                    stock_data_list.append(stock_data)
            
            if stock_data_list:
                stock_report = self.generate_stock_report(stock_data_list)
                report_parts.append(stock_report)
            else:
                report_parts.append("ğŸ“ˆ è‚¡ç¥¨ç›‘æ§\næš‚æ—¶æ— æ³•è·å–è‚¡ç¥¨æ•°æ®\n")
        else:
            self.logger.info("ä¸åœ¨è‚¡ç¥¨æ¨é€æ—¶é—´èŒƒå›´å†…")
        
        # 2. æ–°é—»éƒ¨åˆ†
        if self.should_push_news():
            self.logger.info("è·å–æ–°é—»æ•°æ®...")
            all_articles = []
            
            for source in self.news_sources:
                if source['type'] == 'rss':
                    articles = self.parse_rss_feed(source['url'], source['name'])
                    all_articles.extend(articles)
                # å…¶ä»–ç±»å‹çš„æ–°é—»æºå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
            
            if all_articles:
                news_report = self.generate_news_report(all_articles)
                report_parts.append(news_report)
            else:
                report_parts.append("ğŸ“° æ–°é—»æ‘˜è¦\næš‚æ—¶æ— æ³•è·å–æ–°é—»æ•°æ®\n")
            
            # 3. ç¤¾äº¤åª’ä½“éƒ¨åˆ†ï¼ˆåªåœ¨æœ‰ç›‘æ§å™¨æ—¶æ˜¾ç¤ºï¼‰
            if self.social_monitor:
                self.logger.info("è·å–ç¤¾äº¤åª’ä½“æ•°æ®...")
                social_report = self.social_monitor.run()
                if social_report:  # åªåœ¨æœ‰æ•°æ®æ—¶æ·»åŠ 
                    report_parts.append(social_report)
            else:
                self.logger.info("ç¤¾äº¤åª’ä½“ç›‘æ§æœªå¯ç”¨ï¼Œè·³è¿‡æ˜¾ç¤º")
        else:
            self.logger.info("ä¸åœ¨æ–°é—»æ¨é€æ—¶é—´èŒƒå›´å†…ï¼Œç”Ÿæˆéæ¨é€æ—¶é—´å†…å®¹")
            # ç”Ÿæˆéæ¨é€æ—¶é—´å†…å®¹
            non_push_content = self._generate_non_push_hour_content()
            report_parts.append(non_push_content)
        
        # 3. æ·»åŠ ç³»ç»Ÿä¿¡æ¯
        duration = time.time() - start_time
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        system_info = [
            "",
            "---",
            f"â° æ¨é€æ—¶é—´: {timestamp}",
            f"âš¡ å¤„ç†è€—æ—¶: {self.format_duration(duration)}",
            f"ğŸ“± æ¥æ”¶å·ç : {self._get_whatsapp_number_display()}",
            f"ğŸ”§ ç³»ç»ŸçŠ¶æ€: è¿è¡Œæ­£å¸¸"
        ]
        
        report_parts.append("\n".join(system_info))
        
        # åˆå¹¶æŠ¥å‘Š
        full_report = "\n".join(report_parts)
        
        self.logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(full_report)} å­—ç¬¦")
        
        return True, full_report
    
    def _generate_non_push_hour_content(self) -> str:
        """
        ç”Ÿæˆéæ¨é€æ—¶é—´æ®µçš„å†…å®¹
        
        Returns:
            éæ¨é€æ—¶é—´çš„å†…å®¹æŠ¥å‘Š
        """
        from datetime import datetime
        
        current_time = datetime.now()
        current_hour = current_time.hour
        
        # æ ¹æ®æ—¶é—´ç”Ÿæˆä¸åŒçš„å†…å®¹
        if 0 <= current_hour < 6:  # æ·±å¤œ
            time_period = "æ·±å¤œ"
            suggestion = "å¥½å¥½ä¼‘æ¯ï¼Œæ˜å¤©è§ï¼ğŸŒ™"
        elif 6 <= current_hour < 8:  # æ¸…æ™¨
            time_period = "æ¸…æ™¨" 
            suggestion = "æ–°çš„ä¸€å¤©å¼€å§‹äº†ï¼â˜€ï¸"
        elif 22 <= current_hour <= 23:  # æ™šä¸Š
            time_period = "æ™šä¸Š"
            suggestion = "æ™šå®‰ï¼Œå¥½å¥½ä¼‘æ¯ï¼ğŸŒƒ"
        else:
            time_period = "éæ¨é€æ—¶é—´"
            suggestion = "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
        
        content = [
            f"ğŸŒ™ éæ–°é—»æ¨é€æ—¶é—´æ®µæŠ¥å‘Š",
            f"æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"æ—¶æ®µ: {time_period} ({current_hour}:00)",
            "",
            f"ğŸ’¡ {suggestion}",
            "",
            "ğŸ“‹ ç³»ç»ŸçŠ¶æ€:",
            f"â€¢ æ–°é—»æ¨é€æ—¶é—´: 08:00-22:00",
            f"â€¢ è‚¡ç¥¨æ¨é€æ—¶é—´: 08:00-18:00",
            f"â€¢ å½“å‰æ—¶é—´: {current_hour}:00",
            f"â€¢ ä¸‹æ¬¡æ–°é—»æ¨é€: 08:00",
            "",
            "ğŸ”§ ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå°†åœ¨æ¨é€æ—¶é—´å‘é€å®Œæ•´æ–°é—»",
            ""
        ]
        
        return "\n".join(content)
    
    def run_and_send(self) -> bool:
        """
        è¿è¡Œå¹¶å‘é€æŠ¥å‘Š
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ¨é€å‰å¥åº·æ£€æŸ¥
            self.logger.info("æ‰§è¡Œæ¨é€å‰å¥åº·æ£€æŸ¥...")
            health_ok, health_msg = self.check_system_health()
            
            if not health_ok:
                self.logger.warning(f"å¥åº·æ£€æŸ¥æœªé€šè¿‡: {health_msg}")
                
                # å‘é€å¥åº·å‘Šè­¦
                alert_message = f"âš ï¸ æ¨é€ç³»ç»Ÿå¥åº·å‘Šè­¦\n{health_msg}\n\nç³»ç»Ÿå°†å°è¯•ç»§ç»­æ¨é€ï¼Œä½†å¯èƒ½å¤±è´¥ã€‚"
                self.send_message(alert_message, platforms={"whatsapp": True})
            
            # ç”ŸæˆæŠ¥å‘Š
            success, report = self.run()
            
            if not success:
                self.logger.error("ç”ŸæˆæŠ¥å‘Šå¤±è´¥")
                return False
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            timestamp = self.generate_timestamp()
            filename = f"push_report_{timestamp}.txt"
            self.save_to_file(report, filename)
            
            # å‘é€æŠ¥å‘Š
            if report.strip():
                send_success, result_msg = self.send_message(report)
                self.logger.info(f"å‘é€ç»“æœ: {result_msg}")
                
                # è®°å½•æ¨é€ç»Ÿè®¡
                self._record_push_statistics(send_success, health_ok)
                
                return send_success
            else:
                self.logger.warning("æŠ¥å‘Šä¸ºç©ºï¼Œä¸å‘é€")
                return False
            
        except Exception as e:
            self.logger.error(f"è¿è¡Œæ¨é€å™¨å¼‚å¸¸: {e}")
            return False
    
    def _record_push_statistics(self, success: bool, health_ok: bool):
        """
        è®°å½•æ¨é€ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            success: æ¨é€æ˜¯å¦æˆåŠŸ
            health_ok: å¥åº·æ£€æŸ¥æ˜¯å¦é€šè¿‡
        """
        try:
            import json
            from datetime import datetime
            
            stats_file = "logs/push_statistics.json"
            
            # è¯»å–ç°æœ‰ç»Ÿè®¡
            stats = {}
            if os.path.exists(stats_file):
                with open(stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
            
            # æ›´æ–°ç»Ÿè®¡
            date_str = datetime.now().strftime("%Y-%m-%d")
            if date_str not in stats:
                stats[date_str] = {
                    "total_pushes": 0,
                    "successful_pushes": 0,
                    "failed_pushes": 0,
                    "health_checks_passed": 0,
                    "health_checks_failed": 0
                }
            
            stats[date_str]["total_pushes"] += 1
            if success:
                stats[date_str]["successful_pushes"] += 1
            else:
                stats[date_str]["failed_pushes"] += 1
            
            if health_ok:
                stats[date_str]["health_checks_passed"] += 1
            else:
                stats[date_str]["health_checks_failed"] += 1
            
            # ä¿å­˜ç»Ÿè®¡
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.logger.warning(f"è®°å½•æ¨é€ç»Ÿè®¡å¤±è´¥: {e}")
        finally:
            self.cleanup()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“± ä¼˜åŒ–ç‰ˆæ–°é—»+è‚¡ç¥¨æ¨é€ç³»ç»Ÿ")
    print("=" * 60)
    
    pusher = NewsStockPusherOptimized()
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status = pusher.get_system_status()
    print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    print(f"  æ¨é€å™¨: {status['pusher_name']}")
    print(f"  æ—¶é—´: {status['timestamp']}")
    print(f"  WhatsApp: {status['whatsapp_number']}")
    print(f"  æ¨é€è‚¡ç¥¨: {'âœ…' if status['should_push_stocks'] else 'âŒ'}")
    print(f"  æ¨é€æ–°é—»: {'âœ…' if status['should_push_news'] else 'âŒ'}")
    print(f"  æ•°æ®åº“æ–‡ç« : {status['database_stats'].get('total_articles', 0)}")
    print()
    
    # è¿è¡Œæ¨é€å™¨
    print("ğŸš€ å¼€å§‹æ¨é€...")
    success = pusher.run_and_send()
    
    if success:
        print("âœ… æ¨é€å®Œæˆ")
    else:
        print("âŒ æ¨é€å¤±è´¥")
    
    return 0 if success else 1
    import sys
    sys.exit(main())
